id: SampleClustering
meta:
  title: Clustering
  subtitle: >-
    Cluster cells using their gene expression levels. Choose from many popular
    clustering algorithms
  maintainer:
    name: Olivier Poirion
    email: o.poirion@gmail.com
  description: >
    Clustering, dimension reduction, and visualisation module using classic
    clustering algorithm. The module proposes to first reduce the dimension of
    the dataset, then in a second time to cluster the samples. Most of the
    clustering algorithms will have poor performances if the number of input
    features is too large. Also, some algorithms and dimension reduction
    approaches will be more adapted to some datasets. Most of these algorithms
    are based on the Scikit-Learn implementations, expect for HDBSCAN and our
    own implementation of the autoencoder.
endpoints:
  backend:
    cmd: python ./clustering.py
    type: docker
    image: granatum/py
frontend:
  args:
    - type: select
      label: Clustering method
      choices:
        - label: K-means clustering
          value: kmeans
          description: >-
            Classic clustering algorithm. Pretty slow for large numbers of
            features / samples
        - label: Hierarchical clustering (Ward's criterion)
          value: WARD
          description: >-
            Agglomerative hierarchical clustering algorithm. Faster than
            K-means.
        - label: Density-based spatial clustering of applications with noise (DBSCAN)
          value: DBSCAN
          description: >-
            Very fast but needs a few number of input features (such as 5).
            Also, this algorithm is based on density and thus doesn't require an
            input number of clusters. It is recommended to use DBSCAN with the
            `Find the best number of cluster` option. Finally, density algorithm
            can label samples as outliers if they doesn't fit any clusters
            inferred.
        - label: Hierarchical DBSCAN
          value: HDBSCAN
          description: >-
            A version of DBSCAN that tests different epsilon and propose the
            most stable clusters. This algorithm is very fast but also requires
            a low number of input features (5). We used the the following python
            package (http://hdbscan.readthedocs.io).
        - label: Hierarchical clustering (correlation)
          value: Agglomerative_correlation
          description: >-
            Agglomerative hierarchical clustering algorithm using the Pearson
            correlation distance as metric and an average linkage. This
            algorithm can perform well without reducing the dimension of the
            dataset, and is also fast.
        - label: Gaussian Mixture
          value: Gaussian_Mixture
          description: >-
            Gaussian Mixture algorithm. This algorithm finds a multinomial
            gaussian model for each cluster. Each of the clusters will have a
            specific covariance model which makes this algorithm well adapted
            for clusters having different shapes or density.
        - label: Autoencoder
          value: autoencoder
          description: >-
            Implementation of an autoencoder model. The nodes in the hidden
            bottleneck layers represent the different clusters and each sample
            is assigned to a cluster according to the activities of the hidden
            nodes. This algortihm is more a prototype of a real clustering
            method based on neural network, and the classic methods should be
            overall more performant. Furthermore, the autoencoder seems to be
            more performant when used as a dimension reduction approach, prior
            to clustering.
      default: WARD
      injectInto: selectedClustering
    - type: select
      label: Embedding method
      choices:
        - value: PCA
          description: Principal Component Analysis algorithm.
        - value: IncrementalPCA
          description: >-
            An incremental version of PCA, fitted for very large dataset, and
            gives similar results than PCA. Will be usefull for future
            improvements of Granatum.
        - value: FactorAnalysis
          description: >-
            Factor Analysis (FA) algorithm. An alternative to PCA. Some
            experimental results suggests that FA is efficient to process
            scRNA-seq datasets.
        - value: FastICA
          description: ' Independent Component Analysis (ICA). ICA has been used by multiple studies to pre-process scRNA-seq data. '
        - value: NMF
          description: >-
            Non-negative Matrix factorization (NMF). NMF has been used by few
            study to process scRNA-seq data.
        - value: LatentDirichletAllocation
          description: >-
            Latent Dirichlet Allocation (LDA). This approach has previously benn
            used to process scRNA-seq data.
        - value: MDS
          description: >-
            Multi-Dimensional Scaling (MDS). A classic dimension-reduction
            algorithm
        - value: autoencoder
          description: >-
            Our own implementation of an autoencoder neural-network, based on
            Keras. The activity of the hidden bottleneck layer nodes are used as
            new features. The autoencoder algorithm present the advantage to
            transform the data using non-linear activation function, and
            preliminary results showed that these type of approach revealed
            being efficient to separate single-cell populations.
        - value: None
          description: No dimension reduction methods is used.
      default: PCA
      injectInto: selectedEmbedding
    - type: select
      label: Plotting embedding method
      choices:
        - value: PCA
          description: Principal Component Analysis algorithm.
        - value: IncrementalPCA
          description: >-
            An incremental version of PCA, fitted for very large dataset, and
            gives similar results than PCA. Will be usefull for future
            improvements of Granatum.
        - value: FactorAnalysis
          description: Factor Analysis (FA) algorithm. An alternative to PCA.
        - value: FastICA
          description: Independent Component Analysis (ICA).
        - value: NMF
          description: Non-negative Matrix factorization (NMF).
        - value: TSNE
          description: >-
            t-distributed Stochastic Neighbor Embedding (TSNE). TSNE is a tool
            to visualize the data and is widley used to visualize single-cell
            subpopulations. It is highly recommended to use another dimension
            reduction algorithms to reduce first the dimension of the data prior
            to TNSE.
        - value: MDS
          description: Multi-dimensional scaling.
        - value: ISOMAP
          description: >-
            Non-linear dimensionality reduction through Isometric Mapping
            (ISOMAP). ISOMAP is an earlisest approach of non-linear embedding
            algorithm.
      default: PCA
      injectInto: selectedPlottingEmbedding
    - type: number
      label: Number of components
      default: 30
      injectInto: nComponents
      description: >-
        Defines the number of dimensions used to project the data prior to
        clustering and visualisation.
    - type: number
      label: Number of clusters
      default: 2
      injectInto: nClusters
      description: >-
        Number of input clusters (K) (ignored if the option `Find the best
        number of cluster` is set to True)
    - type: checkbox
      label: Find the best number of cluster
      default: false
      injectInto: findBestNumberOfCluster
      description: >-
        If true, the package will attempt to find automatically thr best number
        of clusters, using the Silhouette score or the BIC score, depending of
        the algorithms. An iteration will be perfomed between K=2 and K=30,
        slowering the analysis.
  exports:
    - kind: sampleMeta
      label: Name of the clustering assignment
      default: Cluster Assignment
      extractFrom: clusters
  imports:
    - kind: assay
      label: The assay to use for clustering
      injectInto: assay
  results:
    - type: iframe
      width: 750
      height: 500
      description: Interactive scatter plot of the clustering results
      extractFrom: plotFigureHtml
    - type: text
      label: Number of clusters
      description: Number of clusters founds
      extractFrom: nClusters
